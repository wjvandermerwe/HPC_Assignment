\section{Problem 2: 2D Convolution using CUDA}
\label{sec:cuda_intro}

Our implementation contains three versions of the \(K\times K\) convolution:

\begin{enumerate}
  \item \texttt{convolutionKernel}: each thread reads its full neighbourhood directly from \emph{global memory};
  \item \texttt{convolutionSharedKernel}: a cooperative tiling version that first stages the required image patch in \emph{shared memory};
  \item \texttt{sequentialConvolution}: a single-threaded CPU reference.  
\end{enumerate}

\subsection{Theoretical Exectations}
\label{ssec:perf_expect}

\begin{itemize}
  \item \textbf{CPU baseline} is limited by lack of parallelism and
        host‑memory bandwidth; runtime grows linearly with
        \(W\!H K^2\).
  \item \textbf{Global‑memory GPU kernel} exploits massive thread
        parallelism and high device bandwidth, giving tens–hundreds\,×
        speed‑up versus the CPU, but still wastes bandwidth due to
        redundant loads. \parencite{nvidia2025ada}
  \item \textbf{Shared‑memory GPU kernel} raises arithmetic intensity:
        the same global bytes now feed many more floating‑point
        operations, so the kernel tends to shift from
        \emph{memory‑bound} to \emph{compute-bound}.  In practice we
        observe a further \(2\!\times\!-5\!\times\) acceleration over
        the global‑memory version on modern GPUs. \parencite{nvidia2025ada}
  \item \textbf{Target Hardware: Nvidia RTX 4080 (Ada Lovelace)} 

  \begin{itemize}
    \item \textbf{Compute.} 9\,728 CUDA cores @ $\sim$2.5 GHz  
          $\Rightarrow$ peak FP32 throughput $\approx$48.7 TFLOP/s. \parencite{techpowerup2025rtx4080}
    \item \textbf{Memory bandwidth.} 16GB GDDR6X on a 256‑bit bus  
          $\Rightarrow$ 716.8 GB/s sustained DRAM bandwidth.
    \item \textbf{On-chip storage.} 128KB L1/shared per SM  
          (up to 100KB usable as shared memory in a single kernel launch);  
          64 MB chip-wide L2 cache. \parencite{techpowerup2025rtx4080}
  \end{itemize}
\end{itemize}


\subsection{Design Considerations}
\begin{itemize}
  \item \textbf{Filter Construction}: Function to create variable kernel sizes (e.g., 3\,$\times$\,3 and 5\,$\times$\,5) via dynamic arrays.
  \item \textbf{Memory Hierarchy}:
    \begin{itemize}
      \item Use \emph{texture memory} for read-only image data to exploit spatial locality and hardware filtering. \parencite{nvidia2025ada}
      \item Employ \emph{shared memory} for tile-based caching of pixel neighborhoods, reducing global memory transactions. Halo Regions are used: The extra border of pixels each block must load into shared memory to compute convolution at its edges. 
    \end{itemize}
  \item \textbf{Border Handling}: Clamp or wrap pixel coordinates when sampling outside image boundaries to prevent convolution artifacts.
  \item \textbf{Thread Mapping}: Assign one CUDA thread per output pixel; choose block dimensions (e.g., 16\,$\times$\,16) to balance occupancy and shared-memory usage.
  \item \textbf{Grid and Block Dimensions}: Define how the image is partitioned; grid size = $\bigl\lceil\frac{W}{B_x}\bigr\rceil\times\bigl\lceil\frac{H}{B_y}\bigr\rceil$, where $W,H$ are image width/height and $B_x,B_y$ are block dims.
  \item \textbf{Synchronization}: Use \texttt{\_\_syncthreads()} to ensure all threads have loaded.
  \item \textbf{Performance Metrics}: Measure throughput in megapixels per second; compare global-memory kernel, shared-memory kernel, and CPU baseline.
  \item \textbf{Warm-up Runs}: Execute kernels once prior to timing to populate caches and eliminate first-launch overhead in measurements.
\end{itemize}

\subsection{Experiment Workflow}
\begin{enumerate}
  \item Initialize CUDA device; include helper utilities (\texttt{helper\_cuda.h}, \texttt{helper\_functions.h}).
  \item Load PGM images into host memory using \texttt{sdkLoadPGM}, recording width and height.
  \item Allocate and populate host filter arrays; copy to device memory via \texttt{cudaMalloc} and \texttt{cudaMemcpy}.
  \item Transfer image data into a \texttt{cudaArray}; configure and create a \texttt{cudaTextureObjectT}.
  \item Calculate block and grid dimensions; determine shared-memory size based on filter radius.
  \item Warmup: Launch each kernel variant once to prime caches and initialize timers.
  \item Execute global-memory, shared-memory, and CPU sequential variants in loops; record average execution times.
  \item Copy results back to host; save PGM output files for visual verification.
  \item Compute performance in Mpixels/s; tabulate and print comparative metrics.
  \item Free host and device memory; destroy texture objects and timers.
\end{enumerate}

\subsection{Results}

The Experiments produced timings and outputs in combinations of the filters with the images provided. below is the results per image and filter pair.

\begin{table}[h]
  \centering
  \caption{Measured throughput of the three convolution variants on the RTX\,4080
           (units: megapixels\,/\,s).}
  \label{tab:conv_results}
  \begin{tabular}{llrrr}
    \toprule
    \textbf{Image} & \textbf{Filter} & \textbf{Regular} & \textbf{Shared} & \textbf{Sequential} \\
    \midrule
    \multirow{3}{*}{image21.pgm}  & emboss  &  8\,968.32 & 10\,377.80 &    6.79 \\
                                  & sharpen & 14\,539.30 & 21\,790.90 &   18.53 \\
                                  & average &  7\,445.16 & 10\,078.60 &    6.73 \\[2pt]
    \multirow{3}{*}{lena\_bw.pgm} & emboss  &  9\,130.76 & 10\,296.30 &    6.87 \\
                                  & sharpen &  8\,080.89 & 19\,533.80 &   18.18 \\
                                  & average &  6\,319.77 &  9\,584.79 &    6.67 \\[2pt]
    \multirow{3}{*}{man.pgm}      & emboss  &  9\,840.24 & 10\,141.00 &    6.83 \\
                                  & sharpen & 15\,312.10 & 19\,814.40 &   18.55 \\
                                  & average &  7\,281.78 & 10\,024.60 &    6.75 \\[2pt]
    \multirow{3}{*}{mandrill.pgm} & emboss  &  9\,978.84 & 10\,345.10 &    6.82 \\
                                  & sharpen & 12\,869.10 & 11\,851.00 &   18.15 \\
                                  & average &  9\,858.74 & 10\,639.00 &    6.89 \\[2pt]
    \multirow{3}{*}{teapot512.pgm}& emboss  &  8\,564.00 & 10\,519.40 &    6.71 \\
                                  & sharpen &  9\,484.23 & 19\,724.90 &   18.17 \\
                                  & average &  9\,204.49 &  9\,436.43 &    6.67 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Performance observations}
\begin{itemize}
  \item Average uplift over the regular kernel is \(\approx30\text{–}50\%\) for \textit{emboss} and \textit{average} filters, and up to \(\approx2\times\) for the larger \textit{sharpen} kernel, demonstrating how on‑chip tiling pays off when each output pixel re‑uses many input elements.

  \item \textit{Sharpen} (a \(5{\times}5\)-like kernel) shows the biggest gap between Regular and Shared (e.g.\ 14.5 \(\rightarrow\) 21.8 GP/s on \texttt{image21.pgm}) because the data-reuse window is wider.  
  The \(3{\times}3\) \textit{emboss} and \textit{average} filters still benefit, but less so, since each block already fits much of the stencil in L1/L2 cache.

  \item Throughput differences across images (\texttt{image21}, \texttt{man}, \texttt{mandrill}, etc.) stay within \(\pm10\%\) for the same kernel, confirming that the bottleneck is memory movement, not arithmetic intensity.

  \item For \texttt{mandrill.pgm} with \textit{sharpen}, the Shared kernel (11.9 GP/s) underperforms the Regular one (12.9 GP/s).  
  Likely causes are sub‑optimal block geometry, bank conflicts, or partial blocks that reduce occupancy.
\end{itemize}


\subsection{Convolution Output Sample}

\begin{figure}[h]
  \centering
  %---------------- image21 example ----------------
  \subcaptionbox{Original}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21.png}}
  \hfill
  \subcaptionbox{Emboss}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_emboss_sha_out.png}}
  \hfill
  \subcaptionbox{Sharpen}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_sharpen_sha_out.png}}
  \hfill
  \subcaptionbox{Average}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_average_sha_out.png}}
  \caption{Convolution results for \texttt{image21.pgm}.}
  \label{fig:image21_results}
\end{figure}
\begin{figure}[h]
  \centering
  %---------------- image21 example ----------------
  \subcaptionbox{Original}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21.png}}
  \hfill
  \subcaptionbox{Emboss}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_emboss_reg_out.png}}
  \hfill
  \subcaptionbox{Sharpen}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_sharpen_reg_out.png}}
  \hfill
  \subcaptionbox{Average}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_average_reg_out.png}}
  \caption{Convolution results for \texttt{image21.pgm}.}
  \label{fig:image21_results}
\end{figure}
\begin{figure}[h]
  \centering
  %---------------- image21 example ----------------
  \subcaptionbox{Original}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21.png}}
  \hfill
  \subcaptionbox{Emboss}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_emboss_seq_out.png}}
  \hfill
  \subcaptionbox{Sharpen}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_sharpen_seq_out.png}}
  \hfill
  \subcaptionbox{Average}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/image21_average_seq_out.png}}
  \caption{Convolution results for \texttt{image21.pgm}.}
  \label{fig:image21_results}
\end{figure}


\begin{figure}[h]
  \centering
  %---------------- image21 example ----------------
  \subcaptionbox{Original}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man.png}}
  \hfill
  \subcaptionbox{Emboss}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_emboss_sha_out.png}}
  \hfill
  \subcaptionbox{Sharpen}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_sharpen_sha_out.png}}
  \hfill
  \subcaptionbox{Average}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_average_sha_out.png}}
  \caption{Convolution results for \texttt{image21.pgm}.}
  \label{fig:image21_results}
\end{figure}
\begin{figure}[h]
  \centering
  %---------------- image21 example ----------------
  \subcaptionbox{Original}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man.png}}
  \hfill
  \subcaptionbox{Emboss}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_emboss_reg_out.png}}
  \hfill
  \subcaptionbox{Sharpen}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_sharpen_reg_out.png}}
  \hfill
  \subcaptionbox{Average}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_average_reg_out.png}}
  \caption{Convolution results for \texttt{image21.pgm}.}
  \label{fig:image21_results}
\end{figure}
\begin{figure}[h]
  \centering
  %---------------- image21 example ----------------
  \subcaptionbox{Original}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man.png}}
  \hfill
  \subcaptionbox{Emboss}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_emboss_seq_out.png}}
  \hfill
  \subcaptionbox{Sharpen}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_sharpen_seq_out.png}}
  \hfill
  \subcaptionbox{Average}[.23\linewidth]{%
    \includegraphics[width=\linewidth]{images/man_average_seq_out.png}}
  \caption{Convolution results for \texttt{image21.pgm}.}
  \label{fig:image21_results}
\end{figure}

